{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f39975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# 1. Wczytanie danych\n",
    "df = pd.read_csv('dataset-tickets-multi-lang-4-20k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 2. Łączenie kolumn subject i body w jeden tekst\n",
    "df['text'] = df['subject'].fillna('') + ' ' + df['body'].fillna('')\n",
    "\n",
    "# 3. Usuwamy wiersze z brakującym typem\n",
    "df = df.dropna(subset=['type'])\n",
    "\n",
    "# 4. Tokenizacja tekstu\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "padded = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# 5. Kodowanie etykiet\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df['type'])\n",
    "labels_cat = to_categorical(labels)\n",
    "\n",
    "# 6. Podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded, labels_cat, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Budowa modelu LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=max_len))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(labels_cat.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 8. Trening\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=5, batch_size=64, verbose=1)\n",
    "\n",
    "# 9. Ewaluacja\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
