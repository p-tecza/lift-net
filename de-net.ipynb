{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20723988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 1. Wczytanie danych\n",
    "# df = pd.read_csv('dataset-tickets-multi-lang-4-20k.csv')\n",
    "\n",
    "df = pd.read_csv('de-tickets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f4285a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "122/122 [==============================] - 54s 418ms/step - loss: 0.7972 - accuracy: 0.6521 - val_loss: 0.5134 - val_accuracy: 0.7677\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 51s 417ms/step - loss: 0.4463 - accuracy: 0.7891 - val_loss: 0.4826 - val_accuracy: 0.7698\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 52s 425ms/step - loss: 0.3035 - accuracy: 0.8653 - val_loss: 0.5452 - val_accuracy: 0.7646\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 52s 429ms/step - loss: 0.1633 - accuracy: 0.9409 - val_loss: 0.7027 - val_accuracy: 0.7297\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 53s 434ms/step - loss: 0.1065 - accuracy: 0.9630 - val_loss: 0.9698 - val_accuracy: 0.6547\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 53s 436ms/step - loss: 0.0654 - accuracy: 0.9776 - val_loss: 0.9400 - val_accuracy: 0.7657\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 53s 434ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.9897 - val_accuracy: 0.7575\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 53s 437ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 1.2218 - val_accuracy: 0.7523\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 54s 439ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 1.1716 - val_accuracy: 0.7513\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 53s 432ms/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 1.3619 - val_accuracy: 0.7657\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 52s 430ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 1.4250 - val_accuracy: 0.7503\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 53s 436ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 1.2651 - val_accuracy: 0.7441\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 52s 427ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 1.5098 - val_accuracy: 0.7472\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 52s 429ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 1.6648 - val_accuracy: 0.7410\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 52s 428ms/step - loss: 0.0316 - accuracy: 0.9902 - val_loss: 1.1871 - val_accuracy: 0.7297\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 52s 427ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 1.4235 - val_accuracy: 0.7749\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 52s 425ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 1.4943 - val_accuracy: 0.7636\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 52s 427ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 1.4278 - val_accuracy: 0.7605\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 53s 431ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 1.7178 - val_accuracy: 0.7698\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 52s 429ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 1.4965 - val_accuracy: 0.7585\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 52s 430ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 1.6723 - val_accuracy: 0.7451\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 53s 435ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 1.3866 - val_accuracy: 0.7616\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 53s 433ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 1.5847 - val_accuracy: 0.7585\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 53s 434ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 1.4326 - val_accuracy: 0.7431\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 53s 434ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 1.6380 - val_accuracy: 0.7564\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 53s 438ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 1.9912 - val_accuracy: 0.7657\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 53s 435ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 1.5748 - val_accuracy: 0.7616\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 53s 435ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 1.5534 - val_accuracy: 0.7677\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 53s 432ms/step - loss: 6.5486e-04 - accuracy: 1.0000 - val_loss: 1.7732 - val_accuracy: 0.7708\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 53s 432ms/step - loss: 1.7640e-04 - accuracy: 1.0000 - val_loss: 1.8881 - val_accuracy: 0.7667\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 53s 438ms/step - loss: 9.9516e-05 - accuracy: 1.0000 - val_loss: 1.9609 - val_accuracy: 0.7667\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 53s 435ms/step - loss: 6.9783e-05 - accuracy: 1.0000 - val_loss: 2.0113 - val_accuracy: 0.7677\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 53s 436ms/step - loss: 9.0661e-05 - accuracy: 1.0000 - val_loss: 2.0648 - val_accuracy: 0.7667\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 53s 432ms/step - loss: 4.8691e-05 - accuracy: 1.0000 - val_loss: 2.1082 - val_accuracy: 0.7667\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 53s 431ms/step - loss: 2.8337e-05 - accuracy: 1.0000 - val_loss: 2.1479 - val_accuracy: 0.7667\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 53s 431ms/step - loss: 2.6910e-05 - accuracy: 1.0000 - val_loss: 2.1834 - val_accuracy: 0.7667\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 52s 430ms/step - loss: 3.3748e-05 - accuracy: 1.0000 - val_loss: 2.2457 - val_accuracy: 0.7688\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 53s 432ms/step - loss: 2.1259e-05 - accuracy: 1.0000 - val_loss: 2.2767 - val_accuracy: 0.7688\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 52s 429ms/step - loss: 1.9775e-05 - accuracy: 1.0000 - val_loss: 2.3094 - val_accuracy: 0.7688\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 52s 429ms/step - loss: 1.5795e-05 - accuracy: 1.0000 - val_loss: 2.3460 - val_accuracy: 0.7688\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 53s 432ms/step - loss: 2.6460e-05 - accuracy: 1.0000 - val_loss: 2.3743 - val_accuracy: 0.7688\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 52s 429ms/step - loss: 1.9260e-05 - accuracy: 1.0000 - val_loss: 2.4107 - val_accuracy: 0.7698\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 53s 432ms/step - loss: 2.2637e-05 - accuracy: 1.0000 - val_loss: 2.4331 - val_accuracy: 0.7698\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 53s 434ms/step - loss: 1.1763e-05 - accuracy: 1.0000 - val_loss: 2.4654 - val_accuracy: 0.7688\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 52s 429ms/step - loss: 7.9799e-06 - accuracy: 1.0000 - val_loss: 2.4842 - val_accuracy: 0.7698\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 53s 433ms/step - loss: 1.1400e-05 - accuracy: 1.0000 - val_loss: 2.5188 - val_accuracy: 0.7677\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 53s 435ms/step - loss: 1.2577e-05 - accuracy: 1.0000 - val_loss: 2.5484 - val_accuracy: 0.7657\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 53s 432ms/step - loss: 5.8268e-06 - accuracy: 1.0000 - val_loss: 2.5722 - val_accuracy: 0.7636\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 52s 429ms/step - loss: 1.1183e-05 - accuracy: 1.0000 - val_loss: 2.6172 - val_accuracy: 0.7688\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 53s 434ms/step - loss: 8.3856e-06 - accuracy: 1.0000 - val_loss: 2.6304 - val_accuracy: 0.7667\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 2.9931 - accuracy: 0.7475\n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 2. Łączenie kolumn subject i body w jeden tekst\n",
    "df['text'] = df['subject'].fillna('') + ' ' + df['body'].fillna('')\n",
    "\n",
    "# 3. Usuwamy wiersze z brakującym typem\n",
    "df = df.dropna(subset=['type'])\n",
    "\n",
    "# 4. Tokenizacja tekstu\n",
    "max_words = 20000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "padded = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# 5. Kodowanie etykiet\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df['type'])\n",
    "labels_cat = to_categorical(labels)\n",
    "\n",
    "# 6. Podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded, labels_cat, test_size=0.2, random_state=42)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 7. Budowa modelu LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 256, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(labels_cat.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 8. Trening\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# 9. Ewaluacja\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
